{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Java\\jdk1.8.0_221\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SPARK_HOME'] = 'D:\\spark'\n",
    "os.environ[\"JAVA_HOME\"] = 'D:\\Java\\jdk1.8.0_221'\n",
    "\n",
    "! echo %JAVA_HOME%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:06:34.224739Z",
     "start_time": "2020-09-04T07:06:30.172063Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\workspace\\uade\\aa\\ES_Spark_Recommendation.ipynb Celda 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/uade/aa/ES_Spark_Recommendation.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/uade/aa/ES_Spark_Recommendation.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/workspace/uade/aa/ES_Spark_Recommendation.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mappName(\u001b[39m\"\u001b[39;49m\u001b[39mrecommendation_system\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mgetOrCreate()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/uade/aa/ES_Spark_Recommendation.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m spark\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\session.py:269\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m     sparkConf\u001b[39m.\u001b[39mset(key, value)\n\u001b[0;32m    268\u001b[0m \u001b[39m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39;49mgetOrCreate(sparkConf)\n\u001b[0;32m    270\u001b[0m \u001b[39m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[39m# by all sessions.\u001b[39;00m\n\u001b[0;32m    272\u001b[0m session \u001b[39m=\u001b[39m SparkSession(sc, options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pyspark\\context.py:483\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m         SparkContext(conf\u001b[39m=\u001b[39;49mconf \u001b[39mor\u001b[39;49;00m SparkConf())\n\u001b[0;32m    484\u001b[0m     \u001b[39massert\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pyspark\\context.py:195\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m gateway \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m gateway\u001b[39m.\u001b[39mgateway_parameters\u001b[39m.\u001b[39mauth_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not allowed as it is a security risk.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m     )\n\u001b[1;32m--> 195\u001b[0m SparkContext\u001b[39m.\u001b[39;49m_ensure_initialized(\u001b[39mself\u001b[39;49m, gateway\u001b[39m=\u001b[39;49mgateway, conf\u001b[39m=\u001b[39;49mconf)\n\u001b[0;32m    196\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_init(\n\u001b[0;32m    198\u001b[0m         master,\n\u001b[0;32m    199\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m         udf_profiler_cls,\n\u001b[0;32m    209\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pyspark\\context.py:417\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_gateway:\n\u001b[1;32m--> 417\u001b[0m         SparkContext\u001b[39m.\u001b[39m_gateway \u001b[39m=\u001b[39m gateway \u001b[39mor\u001b[39;00m launch_gateway(conf)\n\u001b[0;32m    418\u001b[0m         SparkContext\u001b[39m.\u001b[39m_jvm \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_gateway\u001b[39m.\u001b[39mjvm\n\u001b[0;32m    420\u001b[0m     \u001b[39mif\u001b[39;00m instance:\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pyspark\\java_gateway.py:106\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.1\u001b[39m)\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava gateway process exited before sending its port number\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(conn_info_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m info:\n\u001b[0;32m    109\u001b[0m     gateway_port \u001b[39m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"recommendation_system\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:13:50.824295Z",
     "start_time": "2020-09-04T07:13:36.298346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000BEZV7M</td>\n",
       "      <td>Extech RH401 Triple Display Hygro Thermometer ...</td>\n",
       "      <td>Extech</td>\n",
       "      <td>[Appliances, Parts &amp; Accessories, Humidifier P...</td>\n",
       "      <td>Humidity Meters</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                              title   brand  \\\n",
       "0  B000BEZV7M  Extech RH401 Triple Display Hygro Thermometer ...  Extech   \n",
       "\n",
       "                                            category    main_category  \\\n",
       "0  [Appliances, Parts & Accessories, Humidifier P...  Humidity Meters   \n",
       "\n",
       "                                               image  \n",
       "0  [https://images-na.ssl-images-amazon.com/image...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "        \n",
    "def getMetaData(path):\n",
    "    data = []\n",
    "    data_schema =  [\n",
    "                       StructField(\"asin\", StringType(), True),\n",
    "                       StructField(\"title\", StringType(), True),\n",
    "                       StructField(\"brand\", StringType(), True),\n",
    "                       StructField(\"category\", ArrayType(StringType(), True), True),\n",
    "                       StructField(\"main_category\", StringType(), True),\n",
    "                       StructField(\"image\", ArrayType(StringType(), True), True)\n",
    "                   ]\n",
    "    final_schema = StructType(fields=data_schema)\n",
    "    for d in parse(path):\n",
    "        review = {}\n",
    "        review['asin'] = d['asin']\n",
    "        review['title'] = d['title']\n",
    "        review['brand'] = d['brand']\n",
    "        review['category'] = d['category']\n",
    "#         print(d['category'])\n",
    "        review['main_category'] = next(reversed(d['category']), None) if len(d['category'])!= 0 else ''\n",
    "        review['image'] = d['image']\n",
    "        data.append(review)\n",
    "#   print(df)\n",
    "    return spark.createDataFrame(data, schema=final_schema)\n",
    "\n",
    "product_data = getMetaData('./data/meta_Appliances.json.gz')\n",
    "product_data = product_data.dropDuplicates(['asin'])\n",
    "product_data.limit(1).toPandas()\n",
    "# product_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:14:08.645512Z",
     "start_time": "2020-09-04T07:14:03.932571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|       main_category|count|\n",
      "+--------------------+-----+\n",
      "| Parts & Accessories| 4513|\n",
      "|Refrigerator Part...| 3733|\n",
      "|Washer Parts & Ac...| 2270|\n",
      "|Dishwasher Parts ...| 1790|\n",
      "|Range Parts & Acc...| 1710|\n",
      "|       Water Filters| 1572|\n",
      "|   Replacement Parts| 1556|\n",
      "|Cooktop Parts & A...| 1171|\n",
      "|         Range Hoods|  951|\n",
      "|Humidifier Parts ...|  887|\n",
      "|                    |  805|\n",
      "|       Refrigerators|  722|\n",
      "|Oven Parts & Acce...|  645|\n",
      "|          Ice Makers|  453|\n",
      "|            Cooktops|  436|\n",
      "| Freestanding Ranges|  412|\n",
      "|               Knobs|  406|\n",
      "|Freezer Parts & A...|  360|\n",
      "|Built-In Dishwashers|  357|\n",
      "|         Accessories|  341|\n",
      "|             Washers|  302|\n",
      "|                Bins|  273|\n",
      "|              Dryers|  253|\n",
      "|               Vents|  243|\n",
      "|Dryer Parts & Acc...|  235|\n",
      "|              Motors|  224|\n",
      "|             Filters|  213|\n",
      "|     Humidity Meters|  185|\n",
      "|   Replacement Wicks|  177|\n",
      "|Refrigerators, Fr...|  175|\n",
      "|Ranges, Ovens & C...|  169|\n",
      "|Range Hood Parts ...|  162|\n",
      "|           Drip Pans|  160|\n",
      "|             Shelves|  140|\n",
      "|Beverage Refriger...|  137|\n",
      "|             Burners|  130|\n",
      "|        Lint Screens|  123|\n",
      "|             Handles|  118|\n",
      "|   Single Wall Ovens|  108|\n",
      "|         Drain Pumps|  107|\n",
      "|               Hoses|   87|\n",
      "|             Baskets|   85|\n",
      "|          Kegerators|   84|\n",
      "|              Ranges|   83|\n",
      "|Food Waste Dispos...|   82|\n",
      "|   Double Wall Ovens|   80|\n",
      "|    Upright Freezers|   73|\n",
      "|Parts &amp; Acces...|   71|\n",
      "|         Dishwashers|   61|\n",
      "|     Slide-In Ranges|   60|\n",
      "|      Chest Freezers|   55|\n",
      "|           Fasteners|   53|\n",
      "|    Plug Receptacles|   52|\n",
      "|    Washers & Dryers|   38|\n",
      "|Trash Compactor P...|   34|\n",
      "|Portable & Counte...|   33|\n",
      "|   Specialty Laundry|   32|\n",
      "|        Burner Rings|   31|\n",
      "|               Doors|   30|\n",
      "|Humidifier Parts ...|   28|\n",
      "|All-in-One Combin...|   27|\n",
      "|  Absorption Sleeves|   25|\n",
      "|Range Parts &amp;...|   22|\n",
      "|            Freezers|   22|\n",
      "|Combination Micro...|   21|\n",
      "|           Chemicals|   21|\n",
      "|Garbage Disposals...|   18|\n",
      "|Refrigerator Part...|   18|\n",
      "|             Blowers|   18|\n",
      "|  Laundry Appliances|   17|\n",
      "|          Wall Ovens|   16|\n",
      "|    Trash Compactors|   16|\n",
      "|Stacked Washer & ...|   12|\n",
      "|Dishwasher Parts ...|   12|\n",
      "|     Warming Drawers|   10|\n",
      "|Washer Parts &amp...|   10|\n",
      "|Range Hood Parts ...|    9|\n",
      "|Wine Cellar Parts...|    8|\n",
      "|Cooktop Parts &am...|    6|\n",
      "|        Exhaust Fans|    6|\n",
      "|              Grills|    6|\n",
      "|Portable &amp; Co...|    5|\n",
      "|Oven Parts &amp; ...|    4|\n",
      "|Refrigerators, Fr...|    3|\n",
      "|Food Waste Dispos...|    3|\n",
      "|Trash Compactor P...|    3|\n",
      "|Dryer Parts &amp;...|    3|\n",
      "|      Drop-In Ranges|    2|\n",
      "|Beverage Refriger...|    2|\n",
      "|Ranges, Ovens &am...|    2|\n",
      "|Freezer Parts &am...|    2|\n",
      "|There is no diffe...|    1|\n",
      "|Combination Micro...|    1|\n",
      "|Fringed trim make...|    1|\n",
      "|              XOP36S|    1|\n",
      "|Garbage Disposals...|    1|\n",
      "|Wine Cellar Parts...|    1|\n",
      "|        Quick-drying|    1|\n",
      "|This pump is inte...|    1|\n",
      "|Perfect gift for ...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_data.groupBy(\"main_category\").count().orderBy(col('count').desc()).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:14:22.425243Z",
     "start_time": "2020-09-04T07:14:21.940316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'PRINHYLTPDL1275',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'EzFBPnY5SauC7OJNNutBtA',\n",
       " 'version': {'number': '7.9.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'deb',\n",
       "  'build_hash': 'a479a2a7fce0389512d6a9361301708b92dff667',\n",
       "  'build_date': '2020-08-11T21:36:48.204330Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.6.0',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# test your ES instance is running\n",
    "es = Elasticsearch()\n",
    "es.info(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:14:41.430876Z",
     "start_time": "2020-09-04T07:14:39.262089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created indices:\n",
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'products'}\n"
     ]
    }
   ],
   "source": [
    "es.indices.delete(index=\"products\")\n",
    "VECTOR_DIM = 25\n",
    "\n",
    "product_mapping = {\n",
    "    # this mapping definition sets up the metadata fields for the products\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"asin\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"image\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"brand\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"category\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"main_category\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            # the following fields define our model factor vectors and metadata\n",
    "            \"model_factor\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\" : VECTOR_DIM\n",
    "            },\n",
    "            \"model_version\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"model_timestamp\": {\n",
    "                \"type\": \"date\"\n",
    "            }          \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res_products = es.indices.create(index=\"products\", body=product_mapping)\n",
    "\n",
    "print(\"Created indices:\")\n",
    "print(res_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:15:11.769816Z",
     "start_time": "2020-09-04T07:15:11.731465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30239"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " es.count(index=\"products\")['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:15:06.668156Z",
     "start_time": "2020-09-04T07:14:51.497854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product DF count: 30239\n",
      "ES index count: 30239\n"
     ]
    }
   ],
   "source": [
    "product_data.write.format(\"es\").option(\"es.mapping.id\", \"asin\").save(\"products\")\n",
    "num_products_df = product_data.count()\n",
    "num_products_es = es.count(index=\"products\")['count']\n",
    "# check load went ok\n",
    "print(\"Product DF count: {}\".format(num_products_df))\n",
    "print(\"ES index count: {}\".format(num_products_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:00:53.827390Z",
     "start_time": "2020-09-03T05:00:53.721203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 55,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 722, 'relation': 'eq'},\n",
       "  'max_score': 3.7342029,\n",
       "  'hits': [{'_index': 'products',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'B002ACEF9S',\n",
       "    '_score': 3.7342029,\n",
       "    '_source': {'asin': 'B002ACEF9S',\n",
       "     'title': 'Whirlpool W4TXNWFWQ 14.4 Cu. Ft. White Top Freezer Refrigerator',\n",
       "     'brand': 'Whirlpool',\n",
       "     'category': ['Appliances',\n",
       "      'Refrigerators, Freezers & Ice Makers',\n",
       "      'Refrigerators'],\n",
       "     'main_category': 'Refrigerators',\n",
       "     'image': []}},\n",
       "   {'_index': 'products',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'B0074WFW28',\n",
       "    '_score': 3.7342029,\n",
       "    '_source': {'asin': 'B0074WFW28',\n",
       "     'title': 'GE GTH17DBDWW 16.5 Cu. Ft. White Top Freezer Refrigerator - Energy Star',\n",
       "     'brand': 'GE',\n",
       "     'category': ['Appliances',\n",
       "      'Refrigerators, Freezers & Ice Makers',\n",
       "      'Refrigerators'],\n",
       "     'main_category': 'Refrigerators',\n",
       "     'image': ['https://images-na.ssl-images-amazon.com/images/I/21pI5lP8NeL._SS40_.jpg',\n",
       "      'https://images-na.ssl-images-amazon.com/images/I/51F03KwW49L._SS40_.jpg',\n",
       "      'https://images-na.ssl-images-amazon.com/images/I/51tF%2BxVlVZL._SS40_.jpg']}},\n",
       "   {'_index': 'products',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'B00VIVR7O2',\n",
       "    '_score': 3.7342029,\n",
       "    '_source': {'asin': 'B00VIVR7O2',\n",
       "     'title': 'Frigidaire Professional Series Built-In All Refrigerator, All Freezer Combo with Easy Care Stainless (FPFU19F8RF_FPRU19F8RF)',\n",
       "     'brand': 'Kitma',\n",
       "     'category': ['Appliances',\n",
       "      'Refrigerators, Freezers & Ice Makers',\n",
       "      'Refrigerators'],\n",
       "     'main_category': 'Refrigerators',\n",
       "     'image': ['https://images-na.ssl-images-amazon.com/images/I/41kK2HpXFVL._SX38_SY50_CR,0,0,38,50_.jpg',\n",
       "      'https://images-na.ssl-images-amazon.com/images/I/41WOLBqdRaL._SX38_SY50_CR,0,0,38,50_.jpg',\n",
       "      'https://images-na.ssl-images-amazon.com/images/I/511-mTbRdxL._SX38_SY50_CR,0,0,38,50_.jpg']}}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.search(index=\"products\", q=\"main_category:Refrigerators\", size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T08:46:26.653800Z",
     "start_time": "2020-09-03T08:46:15.332596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1118461304</td>\n",
       "      <td>A3NHUQ33CFH3VM</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1118461304</td>\n",
       "      <td>A3SK6VNBQDNBJE</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1118461304</td>\n",
       "      <td>A3SOFHUR27FO3K</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin      reviewerId  rating\n",
       "0  1118461304  A3NHUQ33CFH3VM     5.0\n",
       "1  1118461304  A3SK6VNBQDNBJE     5.0\n",
       "2  1118461304  A3SOFHUR27FO3K     5.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getRatingData(path):\n",
    "    data = []\n",
    "    data_schema = [\n",
    "               StructField(\"asin\", StringType(), True),\n",
    "               StructField(\"reviewerId\", StringType(), True),\n",
    "               StructField(\"rating\", FloatType(), True)]\n",
    "    final_schema = StructType(fields=data_schema)\n",
    "    for d in parse(path):\n",
    "        review = {}\n",
    "        review['asin'] = d['asin']\n",
    "        review['reviewerId'] = d['reviewerID']\n",
    "        review['rating'] = d['overall']\n",
    "        data.append(review)\n",
    "#   print(df)\n",
    "    return spark.createDataFrame(data, schema=final_schema)\n",
    "\n",
    "df_rating= getRatingData('./data/Appliances_all.json.gz')\n",
    "df_rating.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:02:33.402752Z",
     "start_time": "2020-09-03T05:02:22.532653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------+----------------+----------+\n",
      "|      asin|    reviewerId|rating|reviewerId_index|asin_index|\n",
      "+----------+--------------+------+----------------+----------+\n",
      "|1118461304|A3NHUQ33CFH3VM|   5.0|           119.0|    2250.0|\n",
      "|1118461304|A3SK6VNBQDNBJE|   5.0|        154267.0|    2250.0|\n",
      "|1118461304|A3SOFHUR27FO3K|   5.0|         93964.0|    2250.0|\n",
      "|1118461304|A1HOG1PYCAE157|   5.0|        217964.0|    2250.0|\n",
      "|1118461304|A26JGAM6GZMM4V|   5.0|         79756.0|    2250.0|\n",
      "|1118461304|A17K8WANMYHTX2|   5.0|         82127.0|    2250.0|\n",
      "|1118461304|A13IW3A6W43U0G|   5.0|        410633.0|    2250.0|\n",
      "|1118461304|A1ECEGG1MP7J8J|   5.0|        417266.0|    2250.0|\n",
      "|1118461304|A2D5X9G9S3A7RN|   5.0|        414321.0|    2250.0|\n",
      "|1118461304| AP2F86JFRQ205|   5.0|         93636.0|    2250.0|\n",
      "|1118461304|A3VF3A5A3O04E1|   4.0|        252906.0|    2250.0|\n",
      "|1118461304|A14DW5UMQ1M96O|   5.0|        395199.0|    2250.0|\n",
      "|1118461304|A2V7UVKOFG57IW|   4.0|        255448.0|    2250.0|\n",
      "|1118461304|A2BM5NTLX7CES1|   4.0|        158878.0|    2250.0|\n",
      "|1118461304|A1EQ5D5JRSW23K|   5.0|         38276.0|    2250.0|\n",
      "|1118461304|A1R2JUOGIYH6HO|   4.0|        335346.0|    2250.0|\n",
      "|1118461304|A3JRW716H3AX14|   5.0|        112619.0|    2250.0|\n",
      "|1118461304|A3KGLXW3EYDTUH|   4.0|        117231.0|    2250.0|\n",
      "|1118461304|A1B70ZEWQ6UH1A|   3.0|        357820.0|    2250.0|\n",
      "|1118461304|A2I5QME4S7CLFI|   5.0|        422299.0|    2250.0|\n",
      "+----------+--------------+------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(df_rating.columns)-set(['rating'])) ]\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "transformed = pipeline.fit(df_rating).transform(df_rating)\n",
    "transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:04:03.938337Z",
     "start_time": "2020-09-03T05:02:37.654000Z"
    }
   },
   "outputs": [],
   "source": [
    "als=ALS(maxIter=5,regParam=0.09,rank=25,userCol=\"reviewerId_index\",itemCol=\"asin_index\",ratingCol=\"rating\",coldStartStrategy=\"drop\",nonnegative=True)\n",
    "model=als.fit(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:43:50.849997Z",
     "start_time": "2020-09-02T14:43:45.509579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30252"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.itemFactors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T12:55:22.448890Z",
     "start_time": "2020-09-02T12:55:18.289025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=0.03298011012132724\n",
      "+----------+--------------+------+----------------+----------+----------+\n",
      "|      asin|    reviewerId|rating|reviewerId_index|asin_index|prediction|\n",
      "+----------+--------------+------+----------------+----------+----------+\n",
      "|B0053F7TQA| AJPRN1TD1A0SD|   2.0|            40.0|      31.0| 2.0062504|\n",
      "|B0053F7TQA|A1AJW9DILZFTQI|   5.0|            39.0|      31.0|  4.890765|\n",
      "|B0053F7TQA|A1LN48DHHCKLR3|   5.0|            24.0|      31.0|   4.97714|\n",
      "|B0053F7TQA|A3J8IC20SGBS2O|   5.0|            32.0|      31.0|  4.888028|\n",
      "|B000XTJRRA|A1T1YSCDW0PD25|   4.0|            23.0|      34.0| 3.9580224|\n",
      "|B000XTJRRA|A1T1YSCDW0PD25|   4.0|            23.0|      34.0| 3.9580224|\n",
      "|B00AHR3IG4|A1Y4UNHRP312HS|   5.0|            18.0|      28.0|  4.985533|\n",
      "|B00AHR3IG4|A1Y4UNHRP312HS|   5.0|            18.0|      28.0|  4.985533|\n",
      "|B00AHR3IG4|A329823SXZ8IBE|   5.0|            36.0|      28.0|  4.993231|\n",
      "|B00AHR3IG4|A329823SXZ8IBE|   5.0|            36.0|      28.0|  4.993231|\n",
      "|B00DM8JA7Q| AVGG8CYK8K312|   5.0|            31.0|      26.0| 4.8868113|\n",
      "|B00DM8JA7Q|A11SCLK8GDDN3C|   5.0|            20.0|      26.0| 4.8776894|\n",
      "|B00DM8JA7Q|A2HDUVKXR5CM7H|   1.0|            37.0|      26.0| 1.2445582|\n",
      "|B00DM8JA7Q|A26M3TN8QICJ3K|   5.0|            14.0|      26.0| 5.0013313|\n",
      "|B00DM8JA7Q|A2O7BWHBIV1HWZ|   5.0|            46.0|      26.0|  4.874883|\n",
      "|B000VL060M|A34A1UP40713F8|   5.0|            19.0|      27.0|  4.936195|\n",
      "|B000VL060M|A34A1UP40713F8|   5.0|            19.0|      27.0|  4.936195|\n",
      "|B000VL060M|A3B1B4E184FSUZ|   5.0|            43.0|      27.0|  4.988645|\n",
      "|B000VL060M|A3B1B4E184FSUZ|   5.0|            43.0|      27.0|  4.988645|\n",
      "|B0045LLC7K|A3GP2HMB2AFOKF|   5.0|            12.0|      44.0|  4.913916|\n",
      "+----------+--------------+------+----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "predictions=model.transform(transformed)\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(\"RMSE=\"+str(rmse))\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:06:03.533982Z",
     "start_time": "2020-09-03T05:06:02.368840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------------+---------------+\n",
      "| id|        model_factor|   model_version|model_timestamp|\n",
      "+---+--------------------+----------------+---------------+\n",
      "|  0|[0.15479389, 0.48...|ALS_34b5e7b4e040|     1599109562|\n",
      "| 10|[0.59706867, 0.56...|ALS_34b5e7b4e040|     1599109562|\n",
      "+---+--------------------+----------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, current_timestamp, unix_timestamp\n",
    "ver = model.uid\n",
    "ts = unix_timestamp(current_timestamp())\n",
    "product_vectors = model.itemFactors.select(\"id\",\\\n",
    "                                         col(\"features\").alias(\"model_factor\"),\\\n",
    "                                         lit(ver).alias(\"model_version\"),\\\n",
    "                                         ts.alias(\"model_timestamp\"))\n",
    "product_vectors.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:06:12.248600Z",
     "start_time": "2020-09-03T05:06:07.772888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+---------------+----------+\n",
      "|        model_factor|   model_version|model_timestamp|      asin|\n",
      "+--------------------+----------------+---------------+----------+\n",
      "|[0.15479389, 0.48...|ALS_34b5e7b4e040|     1599109571|B000AST3AK|\n",
      "|[0.59706867, 0.56...|ALS_34b5e7b4e040|     1599109571|B0006GVNOA|\n",
      "|[0.11962461, 0.14...|ALS_34b5e7b4e040|     1599109571|B01CTNA1VI|\n",
      "|[0.32039857, 0.04...|ALS_34b5e7b4e040|     1599109571|B00126NABC|\n",
      "|[0.047667623, 0.0...|ALS_34b5e7b4e040|     1599109571|B00UB441HS|\n",
      "|[0.1308046, 0.191...|ALS_34b5e7b4e040|     1599109571|B0042U16YI|\n",
      "|[0.12145985, 0.13...|ALS_34b5e7b4e040|     1599109571|B00W0W8LMK|\n",
      "|[0.2897823, 0.301...|ALS_34b5e7b4e040|     1599109571|B004XLDE5A|\n",
      "|[0.021742053, 0.1...|ALS_34b5e7b4e040|     1599109571|B00W0WXHCO|\n",
      "|[0.7827199, 0.146...|ALS_34b5e7b4e040|     1599109571|B00NIZ0DV0|\n",
      "+--------------------+----------------+---------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asin_index_meta = [\n",
    "    f.metadata for f in transformed.schema.fields if f.name == \"asin_index\"]\n",
    "asin_index_labels = asin_index_meta[0][\"ml_attr\"][\"vals\"]\n",
    "\n",
    "from pyspark.ml.feature import IndexToString\n",
    "\n",
    "reviewerId_converter = IndexToString(inputCol=\"id\", outputCol=\"asin\",   labels=asin_index_labels)\n",
    "PredictedLabels = reviewerId_converter.transform(product_vectors)\n",
    "PredictedLabels = PredictedLabels.drop('id')\n",
    "PredictedLabels.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T13:27:48.684217Z",
     "start_time": "2020-09-02T13:27:44.080838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30252"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictedLabels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:07:46.987512Z",
     "start_time": "2020-09-03T05:07:33.971761Z"
    }
   },
   "outputs": [],
   "source": [
    "PredictedLabels.write.format(\"es\") \\\n",
    "    .option(\"es.mapping.id\", \"asin\") \\\n",
    "    .option(\"es.write.operation\", \"upsert\") \\\n",
    "    .save(\"products\", mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T11:53:46.212377Z",
     "start_time": "2020-09-03T11:53:46.150112Z"
    }
   },
   "outputs": [],
   "source": [
    "def vector_query(query_vec, category,vector_field, cosine=False):\n",
    "    \"\"\"\n",
    "    Construct an Elasticsearch script score query using `dense_vector` fields\n",
    "    \n",
    "    The script score query takes as parameters the query vector (as a Python list)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query_vec : list\n",
    "        The query vector\n",
    "    vector_field : str\n",
    "        The field name in the document against which to score `query_vec`\n",
    "    q : str, optional\n",
    "        Query string for the search query (default: '*' to search across all documents)\n",
    "    cosine : bool, optional\n",
    "        Whether to compute cosine similarity. If `False` then the dot product is computed (default: False)\n",
    "     \n",
    "    Note: Elasticsearch cannot rank negative scores. Therefore, in the case of the dot product, a sigmoid transform\n",
    "    is applied. In the case of cosine similarity, 1.0 is added to the score. In both cases, documents with no \n",
    "    factor vectors are ignored by applying a 0.0 score.\n",
    "    \n",
    "    The query vector passed in will be the user factor vector (if generating recommended items for a user)\n",
    "    or product factor vector (if generating similar items for a given item)\n",
    "    \"\"\"\n",
    "    \n",
    "    if cosine:\n",
    "        score_fn = \"doc['{v}'].size() == 0 ? 0 : cosineSimilarity(params.vector, '{v}') + 1.0\"\n",
    "    else:\n",
    "        score_fn = \"doc['{v}'].size() == 0 ? 0 : sigmoid(1, Math.E, -dotProduct(params.vector, '{v}'))\"\n",
    "       \n",
    "    score_fn = score_fn.format(v=vector_field, fn=score_fn)\n",
    "    \n",
    "    return {\n",
    "    \"query\": {\n",
    "        \"script_score\": {\n",
    "            \"query\" : { \n",
    "                \"bool\" : {\n",
    "                      \"filter\" : {\n",
    "                            \"term\" : {\n",
    "                              \"main_category\" : category\n",
    "                            }\n",
    "                        }\n",
    "                }\n",
    "            },\n",
    "            \"script\": {\n",
    "                \"source\": score_fn,\n",
    "                \"params\": {\n",
    "                    \"vector\": query_vec\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def get_similar(the_id, num=10, index=\"products\", vector_field='model_factor'):\n",
    "    \"\"\"\n",
    "    Given a item id, execute the recommendation script score query to find similar items,\n",
    "    ranked by cosine similarity. We return the `num` most similar, excluding the item itself.\n",
    "    \"\"\"\n",
    "    response = es.get(index=index, id=the_id)\n",
    "    src = response['_source']\n",
    "    if vector_field in src:\n",
    "        query_vec = src[vector_field]\n",
    "        category = src['main_category']\n",
    "        q = vector_query(query_vec, category,vector_field, cosine=True)\n",
    "#         print(q)\n",
    "        results = es.search(index=index, body=q)\n",
    "        hits = results['hits']['hits']\n",
    "        return src,hits[1:num+1]\n",
    "\n",
    "def display_similar(the_id, num=10, es_index=\"products\"):\n",
    "    \"\"\"\n",
    "    Display query product, together with similar product and similarity scores, in a table\n",
    "    \"\"\"\n",
    "    product, recs = get_similar(the_id, num, es_index)\n",
    "       \n",
    "    display(HTML(\"<h2>Get similar products for:</h2>\"))\n",
    "    display(HTML(\"<h4>%s (ASIN - %s)</h4>\" % (product['title'], product['asin'])))\n",
    "    display(HTML(\"<br>\"))\n",
    "    display(HTML(\"<h2>People who liked this product also liked these:</h2>\"))\n",
    "    sim_html = \"<table border=0>\"\n",
    "    i = 0\n",
    "    pd_data = []\n",
    "    for rec in recs:\n",
    "        r_score = rec['_score']\n",
    "        r_title = rec['_source']['title']\n",
    "        r = {}\n",
    "        r['asin'] = rec['_source']['asin']\n",
    "        r['title'] = r_title\n",
    "        r['score'] = r_score\n",
    "        pd_data.append(r)\n",
    "        r_im_url = next(iter(rec['_source']['image']), '')\n",
    "        sim_html += \"<tr><td><h5>%s</h5><img src=%s width=150></img></td><td><h5>%2.3f</h5></td></tr>\" % (r_title, r_im_url, r_score)\n",
    "        i += 1\n",
    "    sim_html += \"</table>\"\n",
    "    pd.set_option('display.max_colwidth', -1) \n",
    "    pd_df = pd.DataFrame (pd_data)\n",
    "    display(HTML(pd_df.to_html()))\n",
    "    display(HTML(sim_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T11:53:51.447805Z",
     "start_time": "2020-09-03T11:53:51.338570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Get similar products for:</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Whirlpool : GI5FSAXVY Refrigerator (ASIN - B001A5HT94)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>People who liked this product also liked these:</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:97: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00VVH5PRE</td>\n",
       "      <td>Samsung RS25J500DSR 36&amp;quot; Freestanding Side by Side Refrigerator with 24.52 cu. ft. Capacity,</td>\n",
       "      <td>1.773148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004Y264RI</td>\n",
       "      <td>KitchenAid KBFS25EWMS Architect Series II 24.8 cu. ft. French Door Refrigerator - Stainless Steel</td>\n",
       "      <td>1.772508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002ACEF9S</td>\n",
       "      <td>Whirlpool W4TXNWFWQ 14.4 Cu. Ft. White Top Freezer Refrigerator</td>\n",
       "      <td>1.749504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00K7LDYWS</td>\n",
       "      <td>Oster 3.25 CF Refrigerator-Black-OSDR325B1</td>\n",
       "      <td>1.727583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00NI9T5ME</td>\n",
       "      <td>Electrolux EI32AR80QS 18.6 Cu. Ft. Stainless Steel Freezerless Refrigerator</td>\n",
       "      <td>1.716890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=0><tr><td><h5>Samsung RS25J500DSR 36&quot; Freestanding Side by Side Refrigerator with 24.52 cu. ft. Capacity,</h5><img src=https://images-na.ssl-images-amazon.com/images/I/41vQpaCWSCL._SX38_SY50_CR,0,0,38,50_.jpg width=150></img></td><td><h5>1.773</h5></td></tr><tr><td><h5>KitchenAid KBFS25EWMS Architect Series II 24.8 cu. ft. French Door Refrigerator - Stainless Steel</h5><img src=https://images-na.ssl-images-amazon.com/images/I/31sdH5IZA9L._SX38_SY50_CR,0,0,38,50_.jpg width=150></img></td><td><h5>1.773</h5></td></tr><tr><td><h5>Whirlpool W4TXNWFWQ 14.4 Cu. Ft. White Top Freezer Refrigerator</h5><img src= width=150></img></td><td><h5>1.750</h5></td></tr><tr><td><h5>Oster 3.25 CF Refrigerator-Black-OSDR325B1</h5><img src= width=150></img></td><td><h5>1.728</h5></td></tr><tr><td><h5>Electrolux EI32AR80QS 18.6 Cu. Ft. Stainless Steel Freezerless Refrigerator</h5><img src= width=150></img></td><td><h5>1.717</h5></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML, display\n",
    "data = display_similar('B001A5HT94', num=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "301a17a29b57d3836b7901af1621afd6d2b1f2298b9c7949191147cf2fea93e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
